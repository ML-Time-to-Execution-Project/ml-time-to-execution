{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package and Parameter Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameter setting\n",
    "tte_path = '../data/data_tte'\n",
    "lob_path = '../data/data_lob'\n",
    "\n",
    "time_span = 100\n",
    "level_span = 10\n",
    "train_val_ratio = 0.8\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# cnn_lstm parameter setting\n",
    "\n",
    "filter_num = 32\n",
    "time_y = 10\n",
    "\n",
    "# MLP parameter setting\n",
    "\n",
    "hidden_size1 = 50\n",
    "hidden_size2 = 20\n",
    "\n",
    "# forward parameter setting\n",
    "\n",
    "epochs =50\n",
    "time_y = 10\n",
    "learning_rate = 0.001\n",
    "censor_weight = 0.1\n",
    "time_weight = 1\n",
    "input_size = 102\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing function\n",
    "# ---------------------------------------------------------------------\n",
    "def prepare_order(data, time_span, level_span, trans):\n",
    "    [N, D] = data.shape\n",
    "    # N:time num D:feature num\n",
    "    df = np.array(data)\n",
    "    if trans == True:\n",
    "        df = (df - df.mean())/(df.std())\n",
    "\n",
    "    # 3 dims: sample,time,feature\n",
    "    dataX = np.zeros((N - time_span, time_span, 4*level_span))\n",
    "\n",
    "    for i in range(time_span, N):\n",
    "        dataX[i - time_span] = df[i - time_span:i, 0:4*level_span]\n",
    "\n",
    "    return dataX\n",
    "\n",
    "\n",
    "def prepare_timex(mess_data, order_index, time_span):\n",
    "    # mess_data = np.array(mess_data)\n",
    "    index_list = map(int, mess_data[:,0])\n",
    "    # index_list = int(mess_data[:,0])\n",
    "\n",
    "    time_feature = [order_index[i-time_span] for i in index_list]\n",
    "\n",
    "    return np.array(time_feature)\n",
    "\n",
    "\n",
    "def prepare_prex(mess_data,trans):\n",
    "    # mess_data = np.array(mess_data)\n",
    "\n",
    "    pre_feature = mess_data[:,4:]\n",
    "    if trans == True:\n",
    "        pre_feature = (pre_feature - pre_feature.mean())/(pre_feature.std())\n",
    "\n",
    "    return pre_feature\n",
    "\n",
    "def prepare_sub_prex(mess_data, lob_mess_data, trans):\n",
    "    mess_data = np.array(mess_data)\n",
    "    lob_mess_data = np.array(lob_mess_data)\n",
    "    index_list = map(int, mess_data[:,0])\n",
    "\n",
    "    pre_sub_feature = [lob_mess_data[i,3:5] for i in index_list]\n",
    "    pre_sub_feature = np.array(pre_sub_feature)\n",
    "    if trans == True:\n",
    "        pre_sub_feature = (pre_sub_feature - pre_sub_feature.mean())/(pre_sub_feature.std())\n",
    "    return pre_sub_feature\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, mess_data, order_data, lob_mess_data, time_span, level_span, trans):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.time_span = time_span\n",
    "        self.level_span = level_span\n",
    "            \n",
    "        # trans the order data into 4 dim data \n",
    "        order_index = prepare_order(order_data, time_span, level_span, trans)\n",
    "\n",
    "        # according the message in mess_data to get the time feature\n",
    "        time_feature = prepare_timex(mess_data, order_index, time_span)\n",
    "\n",
    "        # according the message in mess_data to get the present feature\n",
    "        pre_feature = prepare_prex(mess_data, trans)\n",
    "\n",
    "        # according the order submission information in lob_mess_data to get another present feature\n",
    "        pre_sub_feature = prepare_sub_prex(mess_data, lob_mess_data, trans)\n",
    "\n",
    "        # get the time and censor label\n",
    "        y = mess_data[:,1:3]\n",
    "\n",
    "        if trans==True:\n",
    "            a = y[:,0]\n",
    "            # b = np.log(y[:,1])\n",
    "            b = y[:,1]\n",
    "            b = (b - b.mean())/(b.std())\n",
    "            a = np.expand_dims(a,axis=1)\n",
    "            b = np.expand_dims(b,axis=1)\n",
    "            y = np.concatenate((a,b),axis=1)\n",
    "        # len(x) get the sample num\n",
    "        self.length = len(mess_data)\n",
    "\n",
    "        time_feature = torch.from_numpy(time_feature)\n",
    "        self.time_feature = torch.unsqueeze(time_feature, 1)\n",
    "        self.pre_feature = torch.from_numpy(pre_feature)\n",
    "        self.pre_sub_feature = torch.from_numpy(pre_sub_feature)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.pre_feature = torch.concat((self.pre_feature,self.pre_sub_feature),1)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        # we can return three parameters\n",
    "        return self.time_feature[index], self.pre_feature[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0\n",
      "202\n",
      "202\n",
      "51\n",
      "202\n",
      "202\n",
      "51\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# iterate the file and get dataset list\n",
    "file_name = os.listdir(tte_path)\n",
    "print(np.floor(len(file_name)*0.8))\n",
    "print(int(np.floor(len(file_name) * train_val_ratio)))\n",
    "train_file = file_name[:int(np.floor(len(file_name) * train_val_ratio))]\n",
    "val_file = file_name[int(np.floor(len(file_name) * train_val_ratio)):]\n",
    "# mess_data = np.loadtxt(tte_path+'/'+train_file[0],skiprows=1,encoding='utf-8')\n",
    "# train_file = ['34200_3900_NFLX_2017-05-01_tte.txt']\n",
    "print(len(train_file))\n",
    "print(len(val_file))\n",
    "# train_data_list = []\n",
    "train_dataloader_list = []\n",
    "# val_data_list = []\n",
    "val_dataloader_list = []\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "d=[]\n",
    "for i in train_file:\n",
    "    order_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('orderbook_50.csv') ]\n",
    "    mess_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('message_50.csv') ]\n",
    "    a.append(order_file[0])\n",
    "    b.append(mess_file[0])\n",
    "for i in val_file:\n",
    "    order_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('orderbook_50.csv') ]\n",
    "    mess_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('message_50.csv') ]\n",
    "    c.append(order_file[0])\n",
    "    d.append(mess_file[0])\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(c))\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess_data = np.loadtxt(\"D:\\Postgraduate_Course_Information\\Director Peng\\ML_Time_to_Execution\\execution_torch_code\\data\\data_test_tte/34200_3900_NFLX_2017-05-02_tte.txt\",skiprows=1)\n",
    "index_list = map(int, mess_data[:,0])\n",
    "order_data = np.loadtxt(\"D:\\Postgraduate_Course_Information\\Director Peng\\ML_Time_to_Execution\\execution_torch_code\\data\\data_test_lob/34200_3900_NFLX_2017-05-02_24900000_57900000_orderbook_50.csv\",delimiter = ',')\n",
    "for i in index_list:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 3 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20876/1726775855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 3 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[],[],[]])\n",
    "b=torch.tensor([[1,2,3],[3,4,5]])\n",
    "c=torch.cat((a,b),1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_index = prepare_order(order_data, time_span, level_span, trans=True)\n",
    "\n",
    "        # according the message in mess_data to get the time feature\n",
    "time_feature = prepare_timex(mess_data, order_index, time_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26698, 100, 40)\n",
      "(66958, 100, 40)\n"
     ]
    }
   ],
   "source": [
    "print(time_feature.shape)\n",
    "print(order_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_list = []\n",
    "train_dataloader_list = []\n",
    "# val_data_list = []\n",
    "val_dataloader_list = []\n",
    "\n",
    "\n",
    "for i in train_file[0:2]:\n",
    "    order_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('orderbook_50.csv') ]\n",
    "    mess_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('message_50.csv') ]\n",
    "    mess_data = np.loadtxt(tte_path+'/'+i,skiprows=1)\n",
    "    order_data = np.loadtxt(lob_path+'/'+order_file[0],delimiter = ',')\n",
    "    lob_mess_data = np.loadtxt(lob_path+'/'+mess_file[0],delimiter = ',')\n",
    "    middle_dataset = Dataset(mess_data=mess_data,order_data=order_data,lob_mess_data=lob_mess_data,time_span=time_span,level_span=level_span,trans=True)\n",
    "    middle_dataloader = torch.utils.data.DataLoader(dataset=middle_dataset, batch_size=batch_size, shuffle=True)\n",
    "    train_dataloader_list.append(middle_dataloader)\n",
    "\n",
    "\n",
    "for i in val_file[0:1]:\n",
    "    order_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('orderbook_50.csv') ]\n",
    "    mess_file = [name for name in os.listdir(lob_path) if name.startswith(i[:-8]) and name.endswith('message_50.csv') ]\n",
    "    mess_data = np.loadtxt(tte_path+'/'+i,skiprows=1)\n",
    "    order_data = np.loadtxt(lob_path+'/'+order_file[0],delimiter = ',')\n",
    "    lob_mess_data = np.loadtxt(lob_path+'/'+mess_file[0],delimiter = ',')\n",
    "    middle_dataset = Dataset(mess_data=mess_data,order_data=order_data,lob_mess_data=lob_mess_data,time_span=time_span,level_span=level_span,trans=True)\n",
    "    middle_dataloader = torch.utils.data.DataLoader(dataset=middle_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader_list.append(middle_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 100, 40])\n",
      "torch.Size([64, 27])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([64, 37])\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "cnn_lstm_model = CNNLSTM(filter_num=filter_num, time_y=time_y)\n",
    "data = train_dataloader_list[0]\n",
    "for i in data:\n",
    "    a,b,c=i\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    print(c.shape)\n",
    "    a=a.to(torch.float32)\n",
    "    time_fea = cnn_lstm_model(a)\n",
    "    fea = torch.cat((b,time_fea),dim=1) \n",
    "    print(fea.shape)\n",
    "    k=k+1\n",
    "    if k==1:\n",
    "        break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device figuragtion\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim = (batch size, time, feature)\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, filter_num, time_y):\n",
    "        super().__init__()\n",
    "        self.time_y = time_y\n",
    "        # convolution blocks\n",
    "        # input dimension , output dimension = 4\n",
    "\n",
    "        #(N,1,100,40)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=filter_num, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#           nn.Tanh()\n",
    "            nn.BatchNorm2d(filter_num),\n",
    "            nn.Conv2d(in_channels=filter_num, out_channels=filter_num, kernel_size=(4,1), stride=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(filter_num),\n",
    "        )\n",
    "        #(N,32,100,20)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=filter_num, out_channels=filter_num, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(filter_num),\n",
    "            nn.Conv2d(in_channels=filter_num, out_channels=filter_num, kernel_size=(4,1), stride=(1,1), padding='same'),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(filter_num)\n",
    "        )\n",
    "\n",
    "        #(N,32,100,20)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=filter_num, out_channels=filter_num, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(filter_num)\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "\n",
    "        #(N,32,100,1)\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        #(N,32,100,1)\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        #(N,32,100,1)\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "\n",
    "        # (N,100,192)\n",
    "        self.lstm = nn.LSTM(input_size=filter_num*6, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        # (N,100,64)\n",
    "        self.fc1 = nn.Linear(64, self.time_y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        # (N,192,100,1)\n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        # (N,100,192,1)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        # (N,100,192)\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # (N,100,64)\n",
    "        x = x[:,-1, :]\n",
    "        # (N,1,64)\n",
    "        x = torch.squeeze(x)\n",
    "        # (N,64)\n",
    "        middle_feature = self.fc1(x)\n",
    "        # (N,10)\n",
    "        # forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return middle_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_size=2):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.l3 = nn.Linear(hidden_size2, num_size)\n",
    "        self.norm1 = nn.BatchNorm1d(input_size)\n",
    "        self.norm2 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.norm3 = nn.BatchNorm1d(hidden_size2)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.l1.weight)\n",
    "        nn.init.xavier_uniform_(self.l2.weight)\n",
    "        nn.init.xavier_uniform_(self.l3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.norm1(x)\n",
    "        out = self.l1(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.norm3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward iteration parameter setting\n",
    "\n",
    "criterion1 = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "cnn_lstm_model = CNNLSTM(filter_num=filter_num, time_y=time_y)\n",
    "mlp_model = NeuralNet(input_size=time_y+27, hidden_size1=hidden_size1, hidden_size2=hidden_size2, num_size=2)\n",
    "cnn_lstm_model.to(device)\n",
    "mlp_model.to(device)\n",
    "cnn_lstm_optimizer = torch.optim.Adam(cnn_lstm_model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(cnn_lstm_model, mlp_model, criterion1, criterion2, cnn_lstm_optimizer, mlp_optimizer,\n",
    " train_dataloader_list, val_dataloader_list, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    val_losses = np.zeros(epochs)\n",
    "    best_val_loss = np.inf\n",
    "    best_val_epoch = 0\n",
    "\n",
    "    # same process epoch first and dataloader next\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        # start batch normalization and drop out\n",
    "        cnn_lstm_model.train()\n",
    "        mlp_model.train()\n",
    "\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for train_loader in train_dataloader_list:\n",
    "            for time_fea, pre_fea, targets in train_loader:\n",
    "                # move data to GPU\n",
    "                time_fea, pre_fea, targets = time_fea.to(device, dtype=torch.float), pre_fea.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
    "                censor_label = targets[:,0]\n",
    "                time_label = targets[:,1]\n",
    "                # print(\"inputs.shape:\", inputs.shape)\n",
    "                # zero the parameter gradients\n",
    "\n",
    "                cnn_lstm_optimizer.zero_grad()\n",
    "                mlp_optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                # print(\"about to get model output\")\n",
    "                time_fea = cnn_lstm_model(time_fea)\n",
    "                fea = torch.cat((pre_fea,time_fea),dim=1) \n",
    "                \n",
    "\n",
    "                y_predicted = mlp_model(fea)\n",
    "                out1 = y_predicted[:, 0] \n",
    "                out2 = y_predicted[:, 1]\n",
    "                loss1 = criterion1(out1, censor_label)\n",
    "                loss2 = criterion2(out2, time_label)\n",
    "                # print(\"done getting model output\")\n",
    "                # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "                loss = (censor_weight * loss1 + time_weight * loss2)\n",
    "                train_loss.append(loss.item())\n",
    "                # Backward and optimize\n",
    "                # print(\"about to optimize\")\n",
    "                loss.backward()\n",
    "                cnn_lstm_optimizer.step()\n",
    "                mlp_optimizer.step()\n",
    "                \n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "\n",
    "        # no drop out and the value in BN stays same\n",
    "        cnn_lstm_model.eval()\n",
    "        mlp_model.eval()\n",
    "        val_loss = []\n",
    "        for val_loader in val_dataloader_list:\n",
    "            for time_fea, pre_fea, targets in val_loader:\n",
    "                time_fea, pre_fea, targets = time_fea.to(device, dtype=torch.float), pre_fea.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)     \n",
    "                censor_label = targets[:,0]\n",
    "                time_label = targets[:,1]\n",
    "                time_fea = cnn_lstm_model(time_fea)\n",
    "                fea = torch.cat((pre_fea,time_fea),dim=1) \n",
    "                y_predicted = mlp_model(fea)\n",
    "                out1 = y_predicted[:, 0] \n",
    "                out2 = y_predicted[:, 1]\n",
    "                loss1 = criterion1(out1, censor_label)\n",
    "                loss2 = criterion2(out2, time_label)\n",
    "                # print(\"done getting model output\")\n",
    "                # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "                loss = (time_weight * loss1 + censor_weight * loss2)\n",
    "                val_loss.append(loss.item())\n",
    "        val_loss = np.mean(val_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save(cnn_lstm_model, '../model/cnn_lstm_model_pytorch')\n",
    "            torch.save(mlp_model, './mlp_model_pytorch')\n",
    "            best_val_loss = val_loss\n",
    "            best_val_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {val_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_val_epoch}')\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20876/263643525.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]D:\\APP\\Anaconda3\\envs\\Financial\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:647.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "  2%|▏         | 1/50 [06:19<5:09:56, 379.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/50, Train Loss: 1.0298,           Validation Loss: 18.7818, Duration: 0:06:19.524086, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [09:52<8:03:48, 592.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20876/2860672571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_losses, val_losses = batch_gd(cnn_lstm_model=cnn_lstm_model, mlp_model=mlp_model, criterion1=criterion1, criterion2=criterion2, \n\u001b[0m\u001b[0;32m      2\u001b[0m   cnn_lstm_optimizer=cnn_lstm_optimizer, mlp_optimizer=mlp_optimizer,train_dataloader_list=train_dataloader_list, val_dataloader_list=val_dataloader_list, epochs=epochs)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20876/607747499.py\u001b[0m in \u001b[0;36mbatch_gd\u001b[1;34m(cnn_lstm_model, mlp_model, criterion1, criterion2, cnn_lstm_optimizer, mlp_optimizer, train_dataloader_list, val_dataloader_list, epochs)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;31m# print(\"about to optimize\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                 \u001b[0mcnn_lstm_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mmlp_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APP\\Anaconda3\\envs\\Financial\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APP\\Anaconda3\\envs\\Financial\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(cnn_lstm_model=cnn_lstm_model, mlp_model=mlp_model, criterion1=criterion1, criterion2=criterion2, \n",
    "  cnn_lstm_optimizer=cnn_lstm_optimizer, mlp_optimizer=mlp_optimizer,train_dataloader_list=train_dataloader_list, val_dataloader_list=val_dataloader_list, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "f = plt.gcf()\n",
    "f.savefig('../picture/result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10924/3589099124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = torch.tensor([1,2,3])\n",
    "c = torch.cat((a,b),dim=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "326f373c6e0d43889a92efc6bf1e375f946ae88ffdce40ee1caa691dc5b3ab7b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Financial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
